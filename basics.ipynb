{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1eb938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44f8baf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(\n",
    "#   base_url=\"https://openrouter.ai/api/v1\",\n",
    "#   api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "# )\n",
    "\n",
    "# # First API call with reasoning\n",
    "# response = client.chat.completions.create(\n",
    "#   model=\"openai/gpt-oss-120b:free\",\n",
    "#   messages=[\n",
    "#           {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"How many r's are in the word 'strawberry'?\"\n",
    "#           }\n",
    "#         ]\n",
    "#   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cbead44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbf98cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from groq import Groq\n",
    "\n",
    "# client = Groq()\n",
    "# completion = client.chat.completions.create(\n",
    "#     model=\"qwen/qwen3-32b\",\n",
    "#     messages=[\n",
    "#       {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"Tell me about transformer architecture and how to do it in pytorch\"\n",
    "#       }\n",
    "#     ],\n",
    "#     temperature=0.6,\n",
    "#     max_completion_tokens=4096,\n",
    "#     top_p=0.95,\n",
    "#     reasoning_effort=\"default\",\n",
    "#     stream=True,\n",
    "#     stop=None\n",
    "# )\n",
    "\n",
    "# for chunk in completion:\n",
    "#     print(chunk.choices[0].delta.content or \"\", end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ccedf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    model=\"openai/gpt-oss-120b:free\",\n",
    "    #temperature=None,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebab5c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing great, thank you for asking. How can I help you today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello how are you\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab450b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm2=init_chat_model(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    model=\"gpt-oss-120b:free\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00905f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "message=[\n",
    "    SystemMessage(content=\"You are a funny person\"),\n",
    "    HumanMessage(content=\"how am i today\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82cccbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2=ChatOpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    model=\"gpt-oss-120b:free\",\n",
    "  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51fbd1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I donâ€™t have a crystal ball (or a mindâ€‘reading app), but I can hazard a guess based on the fact that you just typed a questionâ€”so youâ€™re definitely **conscious**, **online**, and **curious**.  \\n\\nIf youâ€™ve had coffee, youâ€™re probably buzzing with energy.  \\nIf youâ€™re in pajamas, youâ€™re probably cozy and possibly plotting world domination from the comfort of your couch.  \\nIf youâ€™re wearing a superhero cape, youâ€™re obviously feeling unstoppable.  \\n\\nIn short: youâ€™re *you*â€”and thatâ€™s already a pretty impressive state of being. Howâ€™s the day treating you so far? ğŸ˜„', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 246, 'prompt_tokens': 82, 'total_tokens': 328, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 116, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'openai/gpt-oss-120b:free', 'system_fingerprint': None, 'id': 'gen-1770098262-OOqnbA3BvPmbpQeF9QrL', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c2214-040a-7c42-bed7-67c73f022f4c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 82, 'output_tokens': 246, 'total_tokens': 328, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 116}})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55ff6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af29d60",
   "metadata": {},
   "source": [
    "PROMPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c1ced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='What is Machine learning')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt=PromptTemplate.from_template(\"What is {user_input}\")\n",
    "prompt.invoke(\"Machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc49d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class llm_schema(BaseModel):\n",
    "    topic: str\n",
    "    fact: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365fefb",
   "metadata": {},
   "source": [
    "CHAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732fb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import init_chat_model\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    ('system',\"you are a helpful friend\"),\n",
    "    ('user',\"write a fun fact about{topic}\")\n",
    "])\n",
    "llm2=init_chat_model(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    model=\"gpt-oss-120b:free\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005df09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "strparser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245d39e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Fun Fact about Tony Stark (a.k.a. Iron\\u202fMan):**  \\n\\nIn the original *Iron Man* comics (debuting in 1963), Tony Starkâ€™s first suit was actually **silver**, not the iconic redâ€‘andâ€‘gold armor we all recognize today. The bright redâ€‘andâ€‘gold color scheme was introduced later, in 1968, when artist **Jack Kirby** redesigned the suit to make it more eyeâ€‘catching on the comicâ€‘book pageâ€”and the rest is history!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe=prompt|llm2|strparser\n",
    "pipe.invoke(\"tell me bout tony stark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2bead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "def dictinary_maker(data:str)->dict:\n",
    "    return {\"content\":data}\n",
    "dict_maker_runnable=RunnableLambda(dictinary_maker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048813c",
   "metadata": {},
   "source": [
    "CHAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9279224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptemp1=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful assistant\"),\n",
    "    (\"human\",\"write a fun fact about{topic}\")\n",
    "])\n",
    "llm_content=init_chat_model(\n",
    "    base_url=\"https://openrouter.ai/api/v1\", \n",
    "    model=\"gpt-oss-120b:free\", \n",
    "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    ")\n",
    "strparser1=StrOutputParser()\n",
    "promptemp2=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a great linkedin content creator\"),\n",
    "    (\"human\",\"write a linkedin post on {content}\")\n",
    "\n",
    "])\n",
    "linkedin_agent=promptemp1|llm_content|strparser1|dict_maker_runnable|promptemp2|llm_content|strparser1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb8edcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=linkedin_agent.invoke(\"Organoid intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1312d90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ **Fun Fact Friday: Miniâ€‘Brains That Can â€œSeeâ€ and Learn!** ğŸ§ ğŸ’¡  \n",
      "\n",
      "Scientists have just taken a giant leap in brainâ€‘onâ€‘aâ€‘chip research: tiny cerebral organoidsâ€”often called â€œminiâ€‘brainsâ€â€”have been taught to respond to light. ğŸŒŸ This is the **first evidence that organoid tissue can exhibit a primitive form of learning**, opening the door to the emerging idea of **â€œorganoid intelligence.â€**  \n",
      "\n",
      "ğŸ”¬ **Why it matters**  \n",
      "1ï¸âƒ£ **A new model for brain research** â€“ Unlike animal models, organoids are humanâ€‘derived, offering a more accurate window into neurodevelopment and disease.  \n",
      "2ï¸âƒ£ **Learning in a dish** â€“ Demonstrating that these structures can adapt to stimuli suggests we can study the fundamentals of learning, memory, and plasticity in a controlled, ethical platform.  \n",
      "3ï¸âƒ£ **Future tech frontier** â€“ Imagine bioâ€‘hybrid systems where living neural tissue interfaces with electronics, leading to novel computing architectures or personalized neuroâ€‘therapies.  \n",
      "\n",
      "ğŸ’­ **What could this mean for us?**  \n",
      "- Faster drug discovery for neurological disorders.  \n",
      "- Ethical, patientâ€‘specific testing grounds for geneâ€‘editing therapies.  \n",
      "- A whole new class of â€œlivingâ€ AI that learns like a brain, not just a silicon circuit.  \n",
      "\n",
      "ğŸ”— **Letâ€™s spark a conversation:**  \n",
      "What opportunitiesâ€”or challengesâ€”do you see emerging from the convergence of organoid biology and artificial intelligence? How might this reshape biotech, neuroscience, or even the broader tech landscape?\n",
      "\n",
      "ğŸ‘‡ Drop your thoughts below! ğŸ‘‡  \n",
      "\n",
      "#Neuroscience #Organoids #BioTech #ArtificialIntelligence #Innovation #FutureOfScience #LearningMachines #ScienceNews #Research #BrainOnAChip\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304f84f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
